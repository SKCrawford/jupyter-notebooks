{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty print token table for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "def print_token_table(sentence, pos=False, tag=True, dependency=True, lemma=False):\n",
    "    \"\"\"Pretty print the linguistics features of each word in a sentence.\n",
    "    If pos is True, then print the part-of-speech (POS). Defaults to True.\n",
    "    If tag is True, then print the tag. Defaults to True.\n",
    "    If dependency is True, then print the dependencies. Defaults to True.\n",
    "\n",
    "    Given a string, return None.\n",
    "    Depends on tabulate.\n",
    "    \"\"\"\n",
    "\n",
    "    # Print the sentence\n",
    "    print(sentence + \"\\n\")\n",
    "\n",
    "    # Create the table headers\n",
    "    headers = []\n",
    "    headers.append(\"Word\")\n",
    "    if pos:\n",
    "        headers.append(\"POS\")\n",
    "        headers.append(\"POS Definition\")\n",
    "    if tag:\n",
    "        headers.append(\"Tag\")\n",
    "        headers.append(\"Tag Definition\")\n",
    "    if dependency:\n",
    "        headers.append(\"Dep.\")\n",
    "        headers.append(\"Dep. Definition\")\n",
    "    if lemma:\n",
    "        headers.append(\"Lemma.\")\n",
    "\n",
    "    # Create the table data\n",
    "    tagged_words = nlp(sentence)\n",
    "    data = []\n",
    "    for word in tagged_words:\n",
    "        entry = []\n",
    "        entry.append(word.text)\n",
    "        if pos:\n",
    "            entry.append(word.pos_)\n",
    "            entry.append(spacy.explain(word.pos_))\n",
    "        if tag:\n",
    "            entry.append(word.tag_)\n",
    "            entry.append(spacy.explain(word.tag_))\n",
    "        if dependency:\n",
    "            entry.append(word.dep_)\n",
    "            entry.append(spacy.explain(word.dep_))\n",
    "        if lemma:\n",
    "            entry.append(word.lemma_)\n",
    "        data.append(entry)\n",
    "\n",
    "    # Print the table\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"github\") + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb tense patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Tense(Enum):\n",
    "    PRESENT_SIMPLE = \"present simple\"\n",
    "    PRESENT_SIMPLE_3 = \"present simple 3rd\"\n",
    "    PAST_SIMPLE = \"past simple\"\n",
    "    FUTURE_SIMPLE = \"future simple\"\n",
    "    FUTURE_SIMPLE_WILL = \"future simple will\"\n",
    "    FUTURE_SIMPLE_BE_GOING_TO = \"future simple be-going-to\"\n",
    "    FUTURE_SIMPLE_BE_GOING_TO_3 = \"future simple be-going-to 3rd\"\n",
    "    PRESENT_CONT = \"present cont\"\n",
    "    PRESENT_CONT_3 = \"present cont 3rd\"\n",
    "    PAST_CONT = \"past cont\"\n",
    "    FUTURE_CONT = \"future cont\"\n",
    "    PRESENT_PERF = \"present perf\"\n",
    "    PRESENT_PERF_3 = \"present perf 3rd\"\n",
    "    PAST_PERF = \"past perf\"\n",
    "    FUTURE_PERF = \"future perf\"\n",
    "    PRESENT_PERF_CONT = \"present perf cont\"\n",
    "    PRESENT_PERF_CONT_3 = \"present perf cont 3rd\"\n",
    "    PAST_PERF_CONT = \"past perf cont\"\n",
    "    FUTURE_PERF_CONT = \"future perf cont\"\n",
    "\n",
    "\n",
    "class Pattern:\n",
    "    name = \"untitled\"\n",
    "    tokens = []\n",
    "\n",
    "    def __init__(self, name, tokens):\n",
    "        self.name = name\n",
    "        self.tokens = tokens\n",
    "        \n",
    "        \n",
    "class PatternSet:\n",
    "    name = \"untitled\"\n",
    "    patterns = None\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.patterns = {}\n",
    "\n",
    "    # Always 1:1\n",
    "    def create(self, name, tokens):\n",
    "        self.patterns[name] = Pattern(name, tokens)\n",
    "\n",
    "    def find(self, name):\n",
    "        return self.patterns[name].tokens\n",
    "\n",
    "    def find_all(self):\n",
    "        return [self.patterns[key] for key in self.patterns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_set = PatternSet(\"verb tenses\")\n",
    "\n",
    "# Simple\n",
    "pattern_set.create(Tense.PRESENT_SIMPLE.value, [\n",
    "    { \"TAG\": \"VBP\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PRESENT_SIMPLE_3.value, [\n",
    "    { \"TAG\": \"VBZ\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PAST_SIMPLE.value, [\n",
    "    { \"TAG\": \"VBD\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_SIMPLE_WILL.value, [\n",
    "    { \"TAG\": \"MD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LOWER\": \"will\" },\n",
    "    { \"TAG\": \"VB\", \"DEP\": \"ROOT\", \"OP\": \"+\" }\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_SIMPLE_BE_GOING_TO.value, [\n",
    "    { \"TAG\": \"VBP\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\", \"LEMMA\": \"go\" },\n",
    "    { \"TAG\": \"TO\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VB\", \"DEP\": \"xcomp\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_SIMPLE_BE_GOING_TO_3.value, [\n",
    "    { \"TAG\": \"VBZ\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\", \"LEMMA\": \"go\" },\n",
    "    { \"TAG\": \"TO\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VB\", \"DEP\": \"xcomp\", \"OP\": \"+\" },\n",
    "])\n",
    "\n",
    "# Continuous/progressive\n",
    "# TODO fix tokens 3-4\n",
    "pattern_set.create(Tense.PRESENT_CONT.value, [\n",
    "    { \"TAG\": \"VBP\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"TO\", \"DEP\": \"aux\", \"OP\": \"?\" },\n",
    "    { \"TAG\": \"VB\", \"DEP\": \"xcomp\", \"OP\": \"!\" },\n",
    "])\n",
    "# TODO fix tokens 3-4\n",
    "pattern_set.create(Tense.PRESENT_CONT_3.value, [\n",
    "    { \"TAG\": \"VBZ\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"TO\", \"DEP\": \"aux\", \"OP\": \"?\" },\n",
    "    { \"TAG\": \"VB\", \"DEP\": \"xcomp\", \"OP\": \"!\" },\n",
    "])\n",
    "pattern_set.create(Tense.PAST_CONT.value, [\n",
    "    { \"TAG\": \"VBD\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_CONT.value, [\n",
    "    { \"TAG\": \"MD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"will\" },        \n",
    "    { \"TAG\": \"VB\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"be\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "\n",
    "# Perfect\n",
    "pattern_set.create(Tense.PRESENT_PERF.value, [\n",
    "    { \"TAG\": \"VBP\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\"  },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PRESENT_PERF_3.value, [\n",
    "    { \"TAG\": \"VBZ\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\" },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PAST_PERF.value, [\n",
    "    { \"TAG\": \"VBD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\" },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_PERF.value, [\n",
    "    { \"TAG\": \"MD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"will\" },        \n",
    "    { \"TAG\": \"VB\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "\n",
    "# Perfect continuous/progressive\n",
    "pattern_set.create(Tense.PRESENT_PERF_CONT.value, [\n",
    "    { \"TAG\": \"VBP\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\"  },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"aux\", \"OP\": \"+\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PRESENT_PERF_CONT_3.value, [\n",
    "    { \"TAG\": \"VBZ\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\"  },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"be\"  },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.PAST_PERF_CONT.value, [\n",
    "    { \"TAG\": \"VBD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\"  },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"be\"  },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])\n",
    "pattern_set.create(Tense.FUTURE_PERF_CONT.value, [\n",
    "    { \"TAG\": \"MD\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"will\" },        \n",
    "    { \"TAG\": \"VB\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"have\"  },\n",
    "    { \"TAG\": \"VBN\", \"DEP\": \"aux\", \"OP\": \"+\", \"LEMMA\": \"be\" },\n",
    "    { \"TAG\": \"VBG\", \"DEP\": \"ROOT\", \"OP\": \"+\" },\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb tense matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "\n",
    "def create_verb_tense_matcher(nlp):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "\n",
    "    # Simple\n",
    "    matcher.add(Tense.PRESENT_SIMPLE.value, [\n",
    "        pattern_set.find(Tense.PRESENT_SIMPLE.value),\n",
    "        pattern_set.find(Tense.PRESENT_SIMPLE_3.value),\n",
    "    ])\n",
    "    matcher.add(Tense.PAST_SIMPLE.value, [\n",
    "        pattern_set.find(Tense.PAST_SIMPLE.value),\n",
    "    ])\n",
    "    matcher.add(Tense.FUTURE_SIMPLE.value, [\n",
    "        pattern_set.find(Tense.FUTURE_SIMPLE_WILL.value),\n",
    "        pattern_set.find(Tense.FUTURE_SIMPLE_BE_GOING_TO.value),\n",
    "        pattern_set.find(Tense.FUTURE_SIMPLE_BE_GOING_TO_3.value),\n",
    "    ])\n",
    "    return matcher\n",
    "\n",
    "#     # Continuous\n",
    "#     matcher.add(Tense.PRESENT_CONT.value, [\n",
    "#         pattern_set.find(Tense.PRESENT_CONT.value),\n",
    "#         pattern_set.find(Tense.PRESENT_CONT_3.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_CONT.value, [\n",
    "#         pattern_set.find(Tense.PAST_CONT.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_CONT.value, [\n",
    "#         pattern_set.find(Tense.FUTURE_CONT.value),\n",
    "#     ])\n",
    "\n",
    "#     # Perfect\n",
    "#     matcher.add(Tense.PRESENT_PERF.value, [\n",
    "#         pattern_set.find(Tense.PRESENT_PERF.value),\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_3.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_PERF.value, [\n",
    "#         pattern_set.find(Tense.PAST_PERF.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_PERF.value, [\n",
    "#         pattern_set.find(Tense.FUTURE_PERF.value),\n",
    "#     ])\n",
    "\n",
    "#     # Perfect continuous\n",
    "#     matcher.add(Tense.PRESENT_PERF_CONT.value, [\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_CONT.value),\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_CONT_3.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_PERF_CONT.value, [\n",
    "#         pattern_set.find(Tense.PAST_PERF_CONT.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_PERF_CONT.value, [\n",
    "#         pattern_set.find(Tense.FUTURE_PERF_CONT),\n",
    "#     ])\n",
    "#     return matcher\n",
    "\n",
    "\n",
    "\n",
    "# def create_verb_tense_matcher(nlp):\n",
    "#     matcher = Matcher(nlp.vocab)\n",
    "\n",
    "#     # Simple\n",
    "#     matcher.add(Tense.PRESENT_SIMPLE.value, [\n",
    "#         pattern_set.find(Tense.PRESENT_SIMPLE.value),\n",
    "#         pattern_set.find(Tense.PRESENT_SIMPLE_3.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_SIMPLE.value, [\n",
    "#         pattern_set.find(Tense.PAST_SIMPLE.value),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_SIMPLE.value, [\n",
    "#         pattern_set.find(Tense.FUTURE_SIMPLE_WILL.value),\n",
    "#         pattern_set.find(Tense.FUTURE_SIMPLE_BE_GOING_TO.value),\n",
    "#         pattern_set.find(Tense.FUTURE_SIMPLE_BE_GOING_TO_3.value),\n",
    "#     ])\n",
    "\n",
    "#     # Continuous\n",
    "#     matcher.add(Tense.PRESENT_CONT, [\n",
    "#         pattern_set.find(Tense.PRESENT_CONT),\n",
    "#         pattern_set.find(Tense.PRESENT_CONT_3),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_CONT, [\n",
    "#         pattern_set.find(Tense.PAST_CONT),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_CONT, [\n",
    "#         pattern_set.find(Tense.FUTURE_CONT),\n",
    "#     ])\n",
    "\n",
    "#     # Perfect\n",
    "#     matcher.add(Tense.PRESENT_PERF, [\n",
    "#         pattern_set.find(Tense.PRESENT_PERF),\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_3),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_PERF, [\n",
    "#         pattern_set.find(Tense.PAST_PERF),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_PERF, [\n",
    "#         pattern_set.find(Tense.FUTURE_PERF),\n",
    "#     ])\n",
    "\n",
    "#     # Perfect continuous\n",
    "#     matcher.add(Tense.PRESENT_PERF_CONT, [\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_CONT),\n",
    "#         pattern_set.find(Tense.PRESENT_PERF_CONT_3),\n",
    "#     ])\n",
    "#     matcher.add(Tense.PAST_PERF_CONT, [\n",
    "#         pattern_set.find(Tense.PAST_PERF_CONT),\n",
    "#     ])\n",
    "#     matcher.add(Tense.FUTURE_PERF_CONT, [\n",
    "#         pattern_set.find(Tense.FUTURE_PERF_CONT),\n",
    "#     ])\n",
    "#     return matcher\n",
    "\n",
    "\n",
    "# class PatternSetMatcher(Matcher):\n",
    "#     pattern_set = None\n",
    "\n",
    "#     def __init__(self, vocab, pattern_set):\n",
    "#         Matcher.__init__(self, vocab)\n",
    "#         self.pattern_set = pattern_set\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return self.pattern_set.name\n",
    "\n",
    "#     def add(self, rulename, rules):\n",
    "#         hashed_rulename = hash(rulename)\n",
    "#         super(PatternSetMatcher, self).add(hashed_rulename, rules)\n",
    "\n",
    "\n",
    "# pattern_set_matcher = PatternSetMatcher(nlp.vocab, pattern_set)\n",
    "# pattern_set_matcher.add(Tense.PRESENT_SIMPLE, [\n",
    "#     pattern_set.find(Tense.PRESENT_SIMPLE),\n",
    "#     pattern_set.find(Tense.PRESENT_SIMPLE_3),\n",
    "# ])\n",
    "\n",
    "\n",
    "def get_best_match(doc, matches):\n",
    "    best_match_rulename = \"\"\n",
    "    best_match_span = \"\"\n",
    "    for (match_id, start, end) in matches:\n",
    "        rulename = nlp.vocab.strings[match_id]\n",
    "        span = doc[start:end]\n",
    "\n",
    "        if len(best_match_span) < len(span):\n",
    "            best_match_rulename = rulename\n",
    "            best_match_span = span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the verb tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_verb_tense(sentence):\n",
    "    \"\"\"Return a sentence's verb and its tense.\n",
    "\n",
    "    Given a string, return a tuple of (rulename, match_text)\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(sentence, str):\n",
    "        raise TypeError(\"determine_verb_tense arg[0] is not a string\")\n",
    "\n",
    "    if not bool(sentence):\n",
    "        raise ValueError(\"determine_verb_tense arg[0] is not truthy\")\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    matcher = create_verb_tense_matcher(nlp)\n",
    "    matches = matcher(doc)\n",
    "\n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    return get_best_match(doc, matches)\n",
    "\n",
    "\n",
    "def print_sentence_and_tense(sentence):\n",
    "    match = detect_verb_tense(sentence)\n",
    "    rulename = \"???\"\n",
    "    span = \"???\"\n",
    "\n",
    "    if match:\n",
    "        (rulename, span) = match\n",
    "\n",
    "    print(f\"{rulename:18} => {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???                => I am silly.\n",
      "???                => You are silly.\n",
      "???                => She is silly.\n",
      "???                => This is silly.\n",
      "???                => I go there.\n",
      "???                => You go there.\n",
      "???                => She goes there.\n",
      "???                => This goes there.\n",
      "???                => I was silly.\n",
      "???                => You were silly.\n",
      "???                => She was silly.\n",
      "???                => This was silly.\n",
      "???                => I went there.\n",
      "???                => You went there.\n",
      "???                => She went there.\n",
      "???                => This went there.\n",
      "???                => I will be silly.\n",
      "???                => You will be silly.\n",
      "???                => She will be silly.\n",
      "???                => This will be silly.\n",
      "???                => I will go there.\n",
      "???                => You will go there.\n",
      "???                => She will go there.\n",
      "???                => This will go there.\n",
      "???                => I am going to be silly.\n",
      "???                => You are going to be silly.\n",
      "???                => She is going to be silly.\n",
      "???                => This is going to be silly.\n",
      "???                => I am going to go there.\n",
      "???                => You are going to go there.\n",
      "???                => She is going to go there.\n",
      "???                => This is going to go there.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "# Simple present\n",
    "sentences += [\n",
    "    \"I am silly.\", \n",
    "    \"You are silly.\",\n",
    "    \"She is silly.\",\n",
    "    \"This is silly.\",\n",
    "    \"I go there.\", \n",
    "    \"You go there.\",\n",
    "    \"She goes there.\",\n",
    "    \"This goes there.\",\n",
    "]\n",
    "\n",
    "# Simple past\n",
    "sentences += [\n",
    "    \"I was silly.\", \n",
    "    \"You were silly.\",\n",
    "    \"She was silly.\",\n",
    "    \"This was silly.\",\n",
    "    \"I went there.\", \n",
    "    \"You went there.\",\n",
    "    \"She went there.\",\n",
    "    \"This went there.\",\n",
    "]\n",
    "\n",
    "# Simple future *will*\n",
    "sentences += [\n",
    "    \"I will be silly.\", \n",
    "    \"You will be silly.\",\n",
    "    \"She will be silly.\",\n",
    "    \"This will be silly.\",\n",
    "    \"I will go there.\",\n",
    "    \"You will go there.\",\n",
    "    \"She will go there.\",\n",
    "    \"This will go there.\",\n",
    "]\n",
    "\n",
    "# Simple future *be going to*\n",
    "sentences += [\n",
    "    \"I am going to be silly.\", \n",
    "    \"You are going to be silly.\",\n",
    "    \"She is going to be silly.\",\n",
    "    \"This is going to be silly.\",\n",
    "    \"I am going to go there.\",\n",
    "    \"You are going to go there.\",\n",
    "    \"She is going to go there.\",\n",
    "    \"This is going to go there.\",\n",
    "]\n",
    "\n",
    "# # Present continuous\n",
    "# sentences += [\n",
    "#     \"I am being silly.\", \n",
    "#     \"You are being silly.\",\n",
    "#     \"She is being silly.\",\n",
    "#     \"This is being silly.\",\n",
    "#     \"I am going there.\",\n",
    "#     \"You are going there.\",\n",
    "#     \"She is going there.\",\n",
    "#     \"This is going there.\",\n",
    "# ]\n",
    "\n",
    "# # Past continuous\n",
    "# sentences += [\n",
    "#     \"I was being silly.\", \n",
    "#     \"You were being silly.\",\n",
    "#     \"She was being silly.\",\n",
    "#     \"This was being silly.\",\n",
    "#     \"I was going there.\",\n",
    "#     \"You were going there.\",\n",
    "#     \"She was going there.\",\n",
    "#     \"This was going there.\",\n",
    "# ]\n",
    "\n",
    "# # Future continuous\n",
    "# sentences += [\n",
    "#     \"I will be being silly.\", \n",
    "#     \"You will be being silly.\",\n",
    "#     \"She will be being silly.\",\n",
    "#     \"This will be being silly.\",\n",
    "#     \"I will be going there.\",\n",
    "#     \"You will be going there.\",\n",
    "#     \"She will be going there.\",\n",
    "#     \"This will be going there.\",\n",
    "# ]\n",
    "\n",
    "# # Present perfect\n",
    "# sentences += [\n",
    "#     \"I have been silly.\",\n",
    "#     \"You have been silly.\", \n",
    "#     \"She has been silly.\", \n",
    "#     \"This has been silly.\", \n",
    "#     \"I have gone there.\",\n",
    "#     \"You have gone there.\",\n",
    "#     \"She has gone there.\",\n",
    "#     \"This has gone there.\",\n",
    "# ]\n",
    "\n",
    "# # Past perfect\n",
    "# sentences += [\n",
    "#     \"I had been silly.\",\n",
    "#     \"You had been silly.\", \n",
    "#     \"She had been silly.\", \n",
    "#     \"This had been silly.\",\n",
    "#     \"I had gone there.\",\n",
    "#     \"You had gone there.\",\n",
    "#     \"She had gone there.\",\n",
    "#     \"This had gone there.\",\n",
    "# ]\n",
    "\n",
    "# # Future perfect\n",
    "# sentences += [\n",
    "#     \"I will have been silly.\",\n",
    "#     \"You will have been silly.\", \n",
    "#     \"She will have been silly.\",\n",
    "#     \"This will have been silly.\",\n",
    "#     \"I will have gone there.\",\n",
    "#     \"You will have gone there.\",\n",
    "#     \"She will have gone there.\",\n",
    "#     \"This will have gone there.\",\n",
    "# ]\n",
    "\n",
    "# # Present perfect continuous\n",
    "# sentences += [\n",
    "#     \"I have been being silly.\",\n",
    "#     \"You have been being silly.\",\n",
    "#     \"She have been being silly.\",\n",
    "#     \"This have been being silly.\",\n",
    "#     \"I have been going there.\",\n",
    "#     \"You have been going there.\",\n",
    "#     \"She has been going there.\",\n",
    "#     \"This has been going there.\",\n",
    "# ]\n",
    "\n",
    "# # Past perfect continuous\n",
    "# sentences += [\n",
    "#     \"I had been being silly.\", \n",
    "#     \"You had been being silly.\",\n",
    "#     \"She had been being silly.\",\n",
    "#     \"This had been being silly.\",\n",
    "#     \"I had been going there.\",\n",
    "#     \"You had been going there.\",\n",
    "#     \"She had been going there.\",\n",
    "#     \"This had been going there.\",\n",
    "# ]\n",
    "\n",
    "# # Future perfect continuous\n",
    "# sentences += [\n",
    "#     \"I will have been being silly.\", \n",
    "#     \"You will have been being silly.\",\n",
    "#     \"She will have been being silly.\",\n",
    "#     \"This will have been being silly.\",\n",
    "#     \"I will have been going there.\",\n",
    "#     \"You will have been going there.\",\n",
    "#     \"She will have been going there.\",\n",
    "#     \"This will have been going there.\",\n",
    "# ]\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    print_sentence_and_tense(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
